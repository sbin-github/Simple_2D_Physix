{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "# from torchsummary import summary\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab6210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550f8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.load('../data/dataset_10steps_4ch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d140115",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8445967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 100, 100]\n",
    "        # Output size: [batch, 3, 100, 100]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 32, 5, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 32, 5, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 4, 5, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bb0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 6, 9, stride=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 8, 7, stride=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(128, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(x.size())\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.size())\n",
    "        x = torch.flatten(x, start_dim=1) # flatten all dimensions except batch\n",
    "        # print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        # print(x.size())\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        # print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138224bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Variational Auto-Encoder Class\"\"\"\n",
    "        super(StepAE, self).__init__()\n",
    "        \n",
    "        self.enc = Autoencoder()\n",
    "\n",
    "    def step(self, x): # For actual run after training\n",
    "        x = self.enc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x): # For training\n",
    "        # Encode x to z\n",
    "        recon1 = self.enc(x)\n",
    "        recon2 = self.enc(recon1)\n",
    "        recon3 = self.enc(recon2)\n",
    "        recon4 = self.enc(recon3)\n",
    "        # recon5 = self.enc(recon4)\n",
    "        \n",
    "        return recon1, recon2, recon3, recon4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f916064",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a324c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_history_real = []\n",
    "disc_history_fake = []\n",
    "rme_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd25f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://uos-deep-learning.tistory.com/16\n",
    "def calc_gradient_penalty(netD, real_data, generated_data):\n",
    "    # GP strength\n",
    "    LAMBDA = 3\n",
    "\n",
    "    b_size = real_data.size()[0]\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(b_size, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.cuda()\n",
    "\n",
    "    interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
    "    interpolated = torch.autograd.Variable(interpolated, requires_grad=True)\n",
    "    interpolated = interpolated.cuda()\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated = netD(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch.autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(prob_interpolated.size()).cuda(),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(b_size, -1)\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return LAMBDA * ((gradients_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d4fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, discnet, train_loader, epochnow):\n",
    "    model.train()\n",
    "    discnet.train()\n",
    "    avg_loss = 0\n",
    "    for step, (x0, _, x1, _, x2, _, x3, _, x4, _) in enumerate(train_loader):\n",
    "        # noisy_x = x + train_noise_level * torch.randn(*x.shape)\n",
    "        # noisy_x = np.clip(noisy_x, 0., 1.)\n",
    "        del _\n",
    "\n",
    "        x0 = x0.permute(0, 3, 1, 2)\n",
    "        x1 = x1.permute(0, 3, 1, 2)\n",
    "        x2 = x2.permute(0, 3, 1, 2)\n",
    "        x3 = x3.permute(0, 3, 1, 2)\n",
    "        x4 = x4.permute(0, 3, 1, 2)\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))\n",
    "        # model.eval()\n",
    "        discnet.train()\n",
    "        discnet.zero_grad()\n",
    "        optimizerD.zero_grad()\n",
    "        r1, r2, r3, r4 = model(x0.cuda())\n",
    "        \n",
    "        # All real\n",
    "        label_size = x1.size(0)\n",
    "        real_label = 1\n",
    "        label = torch.full((label_size,), real_label, dtype=torch.float, device=device)       \n",
    "        for idx, x_ in enumerate([x1, x2, x3, x4]):\n",
    "            output = discnet(x_.cuda()).view(-1)\n",
    "            if idx == 0:\n",
    "                errD_real = criterionD(output, label)\n",
    "            else:\n",
    "                errD_real += criterionD(output, label)\n",
    "        errD_real.backward()\n",
    "        out_real = output.detach().cpu().numpy()\n",
    "\n",
    "        # All fake\n",
    "        fake_label = 0\n",
    "        label.fill_(fake_label)\n",
    "        for idx, r_ in enumerate([r1, r2, r3, r4]):\n",
    "            output = discnet(r_.detach().contiguous()).view(-1)\n",
    "            if idx == 0:\n",
    "                errD_fake = criterionD(output, label)\n",
    "            else:\n",
    "                errD_fake += criterionD(output, label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        grad_penalty = calc_gradient_penalty(netD, x1.cuda(), r1)\n",
    "        grad_penalty += calc_gradient_penalty(netD, x2.cuda(), r2)\n",
    "        grad_penalty += calc_gradient_penalty(netD, x3.cuda(), r3)\n",
    "        grad_penalty += calc_gradient_penalty(netD, x4.cuda(), r4)\n",
    "        grad_penalty = 1*grad_penalty\n",
    "        grad_penalty.backward()\n",
    "\n",
    "        optimizerD.step()\n",
    "        del r1, r2, r3, r4\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        # model.train()\n",
    "        discnet.eval()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        r1, r2, r3, r4 = model(x0.cuda())\n",
    "        label.fill_(real_label)\n",
    "        for idx, r_ in enumerate([r1, r2, r3, r4]):\n",
    "            output = discnet(r_.detach().contiguous()).view(-1)\n",
    "            if idx == 0:\n",
    "                errG = (idx+1)*criterionD(output, label)\n",
    "            else:\n",
    "                errG += (idx+1)*criterionD(output, label)\n",
    "\n",
    "        loss1 = criterion(r1, x1.cuda())\n",
    "        loss2 = criterion(r2, x2.cuda())\n",
    "        loss3 = criterion(r3, x3.cuda())\n",
    "        loss4 = criterion(r4, x4.cuda())\n",
    "        # loss5 = criterion(r5, x5.cuda())\n",
    "        loss = 10*(loss1 + loss2 + loss3 + loss4) + errG\n",
    "        \n",
    "        del x0, x1, x2, x3, x4, r1, r2, r3, r4\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        if step%10 == 0:\n",
    "            print(\"step{}, loss = {}, real = {}, fake = {}\".format(step, loss, np.mean(out_real), (output.mean().item())), errG.mean().item())\n",
    "            disc_history_real.append([out_real])\n",
    "            disc_history_fake.append([output.detach().cpu().numpy()])\n",
    "\n",
    "        if step%100 == 0:\n",
    "            # sys.stdout = open(os.devnull, 'w')\n",
    "            figplot(epochnow, step)\n",
    "            torch.save(model_origin.state_dict(), \"../data/model/\" + timestampStr + \"/new_stepwise_ep{}_{}.pt\".format(epochnow, step))\n",
    "            torch.save(netD.state_dict(), \"../data/model/\" + timestampStr + \"/new_discnet_ep{}_{}.pt\".format(epochnow, step))\n",
    "            np.save(\"../data/model/\" + timestampStr +\"/disc_history_fake\", disc_history_fake)\n",
    "            np.save(\"../data/model/\" + timestampStr +\"/disc_history_real\", disc_history_real)\n",
    "            np.save(\"../data/model/\" + timestampStr +\"/loss_history\", loss_history)\n",
    "            # sys.stdout = sys.__stdout__\n",
    "\n",
    "    return avg_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb374ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.001)\n",
    "criterionD = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a218858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_origin = StepAE().to(device)\n",
    "# model_origin.load_state_dict(torch.load(\"../data/model/27_May_2022_18_52/new_stepwise_ep5.pt\"))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a513d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneloader = DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def figplot(epochnow, step):\n",
    "    model_origin.eval()\n",
    "    dataiter = iter(oneloader)\n",
    "    images, _, _, _, _, _, _, _, _, _ = dataiter.next()\n",
    "    del _\n",
    "\n",
    "    recon = model_origin.step(images.permute(0, 3, 1, 2).cuda())\n",
    "\n",
    "    # del _\n",
    "    torch.cuda.empty_cache()\n",
    "    # get sample outputs\n",
    "\n",
    "    steps = 100\n",
    "    skip = int(steps/10)\n",
    "    \n",
    "    plt.figure(figsize=(6, 24))\n",
    "    ax=plt.subplot(12,1,1)\n",
    "    plt.imshow(images.permute(0,3,1,2).view(1,4,100,100).cpu()[0][:-1].permute(1,2,0))\n",
    "    ax=plt.subplot(12,1,2)\n",
    "    output = recon.detach().view(1, 4, 100, 100).cpu()[0][:-1].permute(1,2,0)\n",
    "    plt.imshow(output)\n",
    "    ii = 0\n",
    "    for i in range(steps):\n",
    "        recon = model_origin.step(recon)\n",
    "        # del _\n",
    "        \n",
    "        if i%skip == 0:\n",
    "            ii+=1\n",
    "            ax = plt.subplot(12, 1, ii + 2)\n",
    "            # print(i)\n",
    "            # output is resized into a batch of iages\n",
    "            # use detach when it's an output that requires_grad\n",
    "            output = recon.detach().view(1, 4, 100, 100).cpu()[0][:-1].permute(1, 2, 0)\n",
    "            # print(output.min(), output.max())\n",
    "            plt.imshow(output)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            del output\n",
    "            torch.cuda.empty_cache()\n",
    "    plt.savefig(\"../data/model/\"+timestampStr+\"/fig_{}_{}.png\".format(epochnow, step))\n",
    "    torch.save(images, \"../data/model/\"+timestampStr+\"/input_{}_{}.pt\".format(epochnow,step))\n",
    "    del images\n",
    "    del recon\n",
    "    del dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e091ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbin_LAB\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0, loss = 70.63536834716797, real = 0.4985376000404358, fake = 0.5112959146499634 4.694141864776611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step10, loss = 61.996280670166016, real = 0.510780930519104, fake = 0.5124908089637756 4.694118022918701\n",
      "step20, loss = 58.589290618896484, real = 0.5357590913772583, fake = 0.48481470346450806 4.790078163146973\n",
      "step30, loss = 55.25218963623047, real = 0.5883305668830872, fake = 0.4499776363372803 4.924103736877441\n",
      "step40, loss = 48.96773147583008, real = 0.5600725412368774, fake = 0.4149225950241089 5.0257744789123535\n",
      "step50, loss = 41.32895278930664, real = 0.554485023021698, fake = 0.4413851499557495 4.953170299530029\n",
      "step60, loss = 37.81866455078125, real = 0.4953902065753937, fake = 0.45440906286239624 4.904299736022949\n",
      "step70, loss = 34.01366424560547, real = 0.5679348707199097, fake = 0.44784823060035706 4.917586326599121\n",
      "step80, loss = 27.38539695739746, real = 0.4920068085193634, fake = 0.2357913702726364 5.891550064086914\n",
      "step90, loss = 19.473018646240234, real = 0.36284852027893066, fake = 0.3134150803089142 5.500545024871826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step100, loss = 15.046817779541016, real = 0.4252587556838989, fake = 0.4146551787853241 5.116541862487793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step110, loss = 12.133642196655273, real = 0.41835570335388184, fake = 0.33638206124305725 5.411372661590576\n",
      "step120, loss = 11.13662338256836, real = 0.20486682653427124, fake = 0.2072482407093048 5.9826202392578125\n",
      "step130, loss = 10.477280616760254, real = 0.21913498640060425, fake = 0.1992596983909607 5.989882469177246\n",
      "step140, loss = 10.820534706115723, real = 0.22394630312919617, fake = 0.1732425093650818 6.099596977233887\n",
      "step150, loss = 10.960246086120605, real = 0.20415820181369781, fake = 0.21422582864761353 5.925877571105957\n",
      "step160, loss = 10.020387649536133, real = 0.24707481265068054, fake = 0.24664345383644104 5.77810001373291\n",
      "step170, loss = 10.310006141662598, real = 0.19839079678058624, fake = 0.15402917563915253 6.209524154663086\n",
      "step180, loss = 10.761022567749023, real = 0.20378920435905457, fake = 0.2114478349685669 5.922022342681885\n",
      "step190, loss = 10.050278663635254, real = 0.2078353613615036, fake = 0.18877658247947693 6.025461673736572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step200, loss = 10.19670295715332, real = 0.2579230070114136, fake = 0.25831425189971924 5.7047200202941895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step210, loss = 9.954021453857422, real = 0.19646170735359192, fake = 0.17710232734680176 6.079257011413574\n",
      "step220, loss = 9.867599487304688, real = 0.23641636967658997, fake = 0.21306464076042175 5.9170122146606445\n",
      "step230, loss = 9.32101058959961, real = 0.3078468143939972, fake = 0.2522149384021759 5.750130653381348\n",
      "step240, loss = 9.418116569519043, real = 0.22476649284362793, fake = 0.22133396565914154 5.859518527984619\n",
      "step250, loss = 9.13662052154541, real = 0.2146616131067276, fake = 0.24820497632026672 5.703621864318848\n",
      "step260, loss = 8.875105857849121, real = 0.2672754228115082, fake = 0.3122837245464325 5.426907062530518\n",
      "step270, loss = 9.098794937133789, real = 0.21766960620880127, fake = 0.21654485166072845 5.788919448852539\n",
      "step280, loss = 9.470614433288574, real = 0.22431495785713196, fake = 0.19290964305400848 6.0249457359313965\n",
      "step290, loss = 9.506661415100098, real = 0.21150393784046173, fake = 0.2091890424489975 5.947414398193359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step300, loss = 9.192069053649902, real = 0.20758971571922302, fake = 0.2071593850851059 5.9393463134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step310, loss = 9.290597915649414, real = 0.211862251162529, fake = 0.22662362456321716 5.8681488037109375\n",
      "step320, loss = 9.60213851928711, real = 0.19138440489768982, fake = 0.2110813558101654 5.948289394378662\n",
      "step330, loss = 9.273575782775879, real = 0.19665543735027313, fake = 0.18564194440841675 6.051437854766846\n",
      "step340, loss = 9.065618515014648, real = 0.2102275937795639, fake = 0.22982794046401978 5.854373931884766\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_origin.parameters(), lr=0.0001)\n",
    "\n",
    "import datetime\n",
    "dateTimeObj = datetime.datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M\")\n",
    "if timestampStr not in os.listdir(\"../data/model/\"):\n",
    "    os.mkdir(\"../data/model/\"+timestampStr)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_loss = train(model=model_origin, discnet=netD, train_loader=trainloader, epochnow=epoch)\n",
    "    print(\"[Epoch {}] loss:{}\".format(epoch, epoch_loss))\n",
    "    torch.save(model_origin.state_dict(), \"../data/model/\" + timestampStr + \"/new_stepwise_ep{}.pt\".format(epoch))\n",
    "    torch.save(netD.state_dict(), \"../data/model/\" + timestampStr + \"/new_discnet_ep{}.pt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# model_origin = StepAE().to(device)\n",
    "# model_origin.load_state_dict(torch.load(\"cifar10.pt\"))\n",
    "model_origin.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078dbc5",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_origin = StepAE().to(device)\n",
    "model_origin.load_state_dict(torch.load(\"../data/model/27_May_2022_18_52/new_stepwise_ep5.pt\"))\n",
    "model_origin.eval()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c7630e42c07fc97b7bdd3b961f12b9f6f566b7756c390ffd7b074a3a9c10baf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

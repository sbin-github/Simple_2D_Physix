{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(250., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones((10,3,5,5)).cuda()\n",
    "print(a[:,0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((100,100))\n",
    "a[:2,:] += 1\n",
    "print(a[97,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.from_numpy(np.zeros((100,3,10,10)))\n",
    "b = torch.from_numpy(np.ones((100,1,10,10)))\n",
    "c = torch.cat((a,b),1)\n",
    "c.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(c[:,-1].reshape(100,1,10,10).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "for i in range(10):\n",
    "    plt.plot([i] * 10)\n",
    "    camera.snap()\n",
    "animation = camera.animate()\n",
    "animation.save('celluloid_minimal.gif', writer = 'imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"loss_history.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.95741367 10.20103359 10.15862465 ...  4.66714287  4.63087654\n",
      "  5.13131332]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.CoordConvModule import *\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCenc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCenc, self).__init__()\n",
    "        # Input size: [batch, 3, 100, 100]\n",
    "        # Output size: [batch, 3, 100, 100]\n",
    "        self.encoder = nn.Sequential(\n",
    "            CoordConv(in_channels=3, out_channels=32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            CoordConv(in_channels=32, out_channels=32, kernel_size = 5, stride = 1, padding = 2),\n",
    "            CoordConv(in_channels=32, out_channels=3, kernel_size = 3, stride = 1, padding = 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCenc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(np.ones((1,3,100,100))).float()\n",
    "aa = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from learning.CoordConvModule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 100, 100]\n",
    "        # Output size: [batch, 3, 100, 100]\n",
    "        self.encoder = nn.Sequential(\n",
    "            CoordConv(3, 64, kernel_size = 1, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            PrintLayer(),\n",
    "            nn.Conv2d(64, 64, kernel_size = 5, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            PrintLayer(),\n",
    "            nn.Conv2d(64, 64, 7, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(6\n",
    "            nn.LeakyReLU(),\n",
    "            PrintLayer(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 7, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            PrintLayer(),\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            PrintLayer(),\n",
    "            nn.Conv2d(64, 3, 1, stride=1),\n",
    "            PrintLayer(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        # wall = x[:, -1]\n",
    "        # print(wall.size())\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # print(x.size())\n",
    "        # x = torch.cat((x, wall.reshape(len(x), 1, width_fig, width_fig)), 1)\n",
    "        # print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): CoordConv(\n",
       "      (addcoords): AddCoords()\n",
       "      (conv): Conv2d(5, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): PrintLayer()\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): PrintLayer()\n",
       "    (6): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): PrintLayer()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): PrintLayer()\n",
       "    (3): ConvTranspose2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): PrintLayer()\n",
       "    (6): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): PrintLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 100, 100])\n",
      "torch.Size([1, 64, 98, 98])\n",
      "torch.Size([1, 64, 94, 94])\n",
      "torch.Size([1, 64, 98, 98])\n",
      "torch.Size([1, 64, 100, 100])\n",
      "torch.Size([1, 3, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0077,  0.0080,  0.0097,  ...,  0.0093,  0.0075,  0.0065],\n",
       "          [ 0.0079,  0.0108,  0.0127,  ...,  0.0077,  0.0056,  0.0053],\n",
       "          [ 0.0081,  0.0091,  0.0131,  ...,  0.0076,  0.0065,  0.0065],\n",
       "          ...,\n",
       "          [ 0.0052,  0.0048,  0.0077,  ...,  0.0049,  0.0077,  0.0063],\n",
       "          [ 0.0055,  0.0053,  0.0067,  ...,  0.0051,  0.0081,  0.0068],\n",
       "          [ 0.0061,  0.0061,  0.0067,  ...,  0.0050,  0.0069,  0.0072]],\n",
       "\n",
       "         [[-0.0594, -0.0583, -0.0585,  ..., -0.0585, -0.0580, -0.0573],\n",
       "          [-0.0603, -0.0592, -0.0605,  ..., -0.0567, -0.0572, -0.0584],\n",
       "          [-0.0582, -0.0565, -0.0569,  ..., -0.0573, -0.0568, -0.0593],\n",
       "          ...,\n",
       "          [-0.0569, -0.0580, -0.0548,  ..., -0.0556, -0.0559, -0.0588],\n",
       "          [-0.0584, -0.0590, -0.0560,  ..., -0.0580, -0.0582, -0.0599],\n",
       "          [-0.0569, -0.0576, -0.0561,  ..., -0.0576, -0.0575, -0.0583]],\n",
       "\n",
       "         [[ 0.0783,  0.0784,  0.0788,  ...,  0.0809,  0.0815,  0.0811],\n",
       "          [ 0.0779,  0.0769,  0.0754,  ...,  0.0834,  0.0832,  0.0808],\n",
       "          [ 0.0759,  0.0743,  0.0719,  ...,  0.0848,  0.0845,  0.0815],\n",
       "          ...,\n",
       "          [ 0.0775,  0.0777,  0.0771,  ...,  0.0793,  0.0810,  0.0797],\n",
       "          [ 0.0782,  0.0789,  0.0779,  ...,  0.0773,  0.0791,  0.0784],\n",
       "          [ 0.0794,  0.0812,  0.0795,  ...,  0.0784,  0.0802,  0.0796]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(np.ones((1,3,100,100)))\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b4d6e17db2916af3fe64491bf0ea9d2d6710a0e3b1344ba1420057f34ba30e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
